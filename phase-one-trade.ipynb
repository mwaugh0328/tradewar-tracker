{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd             # data package\n",
    "import matplotlib.pyplot as plt # graphics \n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from census import Census # This is new...\n",
    "\n",
    "import requests, io             # internet and input tools  \n",
    "import zipfile as zf            # zip file tools \n",
    "import os  \n",
    "\n",
    "#import weightedcalcs as wc\n",
    "#import numpy as np\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file creates the trade file behind the [Phase One Tracker](https://www.tradewartracker.com/). It proceeds in several steps.\n",
    "\n",
    "1. Grabs the trade data\n",
    "\n",
    "2. Constructs the relavent Phase One product catagories and the associated goals/targets.\n",
    "\n",
    "3. Maps the data to the county level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_type = \"exports\"\n",
    "\n",
    "my_key = \"&key=34e40301bda77077e24c859c6c6c0b721ad73fc7\"\n",
    "# This is my key. I'm nice and I have it posted. If you will be doing more with this\n",
    "# please get your own key!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Grabe the trade data using the Census's API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def census_trade(url, trade_type, country, product_level):\n",
    "    \n",
    "    r = requests.get(url) \n",
    "    \n",
    "    print(r)\n",
    "    \n",
    "    df = pd.DataFrame(r.json()[1:]) # This then converts it to a dataframe\n",
    "    # Note that the first entry is the labels\n",
    "\n",
    "    df.columns = r.json()[0]\n",
    "\n",
    "    df.time = pd.to_datetime(df.time, format=\"%Y-%m\")\n",
    "    # This is so I can call this correctly...\n",
    "    \n",
    "    if trade_type == \"imports\":\n",
    "        \n",
    "        trade_label = country + \"_\" + trade_type\n",
    "        \n",
    "        df[trade_label] = df[\"CON_VAL_MO\"].astype(float)\n",
    "        \n",
    "        df[product_level] = df[\"I_COMMODITY\"].astype(str)\n",
    "        \n",
    "        df.drop([\"CON_VAL_MO\", \"I_COMMODITY\", \"COMM_LVL\"], axis = 1, inplace = True)\n",
    "        \n",
    "    if trade_type == \"exports\":\n",
    "    \n",
    "        trade_label = country + \"_\" + trade_type\n",
    "        \n",
    "        df[trade_label] = df[\"ALL_VAL_MO\"].astype(float)\n",
    "\n",
    "        df[product_level] = df[\"E_COMMODITY\"].astype(str)\n",
    "        \n",
    "        df.drop([\"ALL_VAL_MO\", \"E_COMMODITY\", \"COMM_LVL\"], axis = 1, inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-04-01 00:00:00')"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_use = \"hs?get=E_COMMODITY,ALL_VAL_MO\"\n",
    "\n",
    "url = \"https://api.census.gov/data/timeseries/intltrade/exports/\" + end_use \n",
    "url = url + my_key + \"&time==from+2017-01\" + \"&COMM_LVL=HS6\"\n",
    "\n",
    "url = url + \"&CTY_CODE=5700\"\n",
    "\n",
    "df = census_trade(url, trade_type, \"china\", \"hs6\")\n",
    "\n",
    "df[\"hs4\"] = df[\"hs6\"].str[0:4]\n",
    "\n",
    "df.time.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>CTY_CODE</th>\n",
       "      <th>china_exports</th>\n",
       "      <th>hs6</th>\n",
       "      <th>hs4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150405</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>5700</td>\n",
       "      <td>32903.0</td>\n",
       "      <td>846890</td>\n",
       "      <td>8468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150406</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>5700</td>\n",
       "      <td>3364.0</td>\n",
       "      <td>847030</td>\n",
       "      <td>8470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150407</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>5700</td>\n",
       "      <td>258652.0</td>\n",
       "      <td>847050</td>\n",
       "      <td>8470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150408</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>5700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>847090</td>\n",
       "      <td>8470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150409</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>5700</td>\n",
       "      <td>28690472.0</td>\n",
       "      <td>847130</td>\n",
       "      <td>8471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             time CTY_CODE  china_exports     hs6   hs4\n",
       "150405 2020-04-01     5700        32903.0  846890  8468\n",
       "150406 2020-04-01     5700         3364.0  847030  8470\n",
       "150407 2020-04-01     5700       258652.0  847050  8470\n",
       "150408 2020-04-01     5700            0.0  847090  8470\n",
       "150409 2020-04-01     5700     28690472.0  847130  8471"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Bring in the Phase One Product list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfproducts = pd.read_csv(\".\\\\data\"+ \"\\\\annex-6-1.csv\", dtype = {\"hs4\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phaseone = df.merge(dfproducts, left_on = \"hs4\", right_on = \"hs4\", how = \"left\", indicator = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "concordance = pq.read_table(\".\\\\data\\\\alt_concordance.parquet\").to_pandas()\n",
    "\n",
    "concordance.head()\n",
    "\n",
    "dict_concordance = dict(zip(concordance.hs6,concordance.naics)) \n",
    "\n",
    "df_phaseone[\"naics\"] = df_phaseone[\"hs6\"].map(dict_concordance)\n",
    "\n",
    "df_phaseone[\"naics3\"] = df_phaseone[\"naics\"].str[0:3]\n",
    "# The NAICS codes are for mapping the data to the county level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phaseone.high_catagory = df_phaseone.high_catagory.fillna(\"not in aggreement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the outfiles ``phaseone-tradedata.parquet`` is the main file used in ``phase-one-plots.ipynb`` notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \".\\\\data\"+ \"\\\\phaseone-tradedata.parquet\"\n",
    "\n",
    "pq.write_table(pa.Table.from_pandas(df_phaseone), out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This then constructs the benchmark and goal measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phaseone.set_index(\"time\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = df_phaseone.loc[\"2017\"].groupby(\"high_catagory\")\n",
    "\n",
    "benchmarks = grp.agg({\"china_exports\": \"sum\"})\n",
    "\n",
    "benchmarks.columns = [\"2017 Values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = df_phaseone.loc[\"2020\"].groupby(\"high_catagory\")\n",
    "\n",
    "current = grp.agg({\"china_exports\": \"sum\"})\n",
    "\n",
    "current.columns = [\"2020 Values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks = benchmarks.merge(current, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the goals from the AGREEMENT\n",
    "\n",
    "benchmarks[\"Goals\"] = 32900000000\n",
    "\n",
    "benchmarks.iloc[1,2] = 12500000000\n",
    "\n",
    "benchmarks.iloc[2,2] = 18500000000\n",
    "\n",
    "benchmarks.iloc[3,2] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the ``phaseone-goals.parquet`` file is the data file used to create the bar graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \".\\\\data\"+ \"\\\\phaseone-goals.parquet\"\n",
    "\n",
    "pq.write_table(pa.Table.from_pandas(benchmarks), out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2017 Values</th>\n",
       "      <th>2020 Values</th>\n",
       "      <th>Goals</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_catagory</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. Manufactured Goods</th>\n",
       "      <td>5.043786e+10</td>\n",
       "      <td>1.540667e+10</td>\n",
       "      <td>3.290000e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. Agriculture</th>\n",
       "      <td>2.125617e+10</td>\n",
       "      <td>4.359578e+09</td>\n",
       "      <td>1.250000e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. Energy</th>\n",
       "      <td>1.592206e+10</td>\n",
       "      <td>1.719767e+09</td>\n",
       "      <td>1.850000e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not in aggreement</th>\n",
       "      <td>5.026467e+10</td>\n",
       "      <td>1.017586e+10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        2017 Values   2020 Values         Goals\n",
       "high_catagory                                                  \n",
       "1. Manufactured Goods  5.043786e+10  1.540667e+10  3.290000e+10\n",
       "2. Agriculture         2.125617e+10  4.359578e+09  1.250000e+10\n",
       "3. Energy              1.592206e+10  1.719767e+09  1.850000e+10\n",
       "not in aggreement      5.026467e+10  1.017586e+10           NaN"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### The code below then performs the projection of the data down to the county level\n",
    "\n",
    "The first step is to group on NAICS. Note that how this is constructed is only Phase One coverd products are included. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = df_phaseone.groupby([\"time\",\"naics3\"])\n",
    "\n",
    "exports_by_naics = grp.agg({\"china_exports\": \"sum\"})\n",
    "\n",
    "exports_by_naics.reset_index(inplace = True)\n",
    "\n",
    "exports_by_naics.set_index([\"naics3\"], inplace = True)\n",
    "\n",
    "##################################################################\n",
    "\n",
    "grp = df_phaseone[df_phaseone[\"high_catagory\"] != \"not in aggreement\"].groupby([\"time\",\"naics3\"])\n",
    "\n",
    "exports_phaseone = grp.agg({\"china_exports\": \"sum\"})\n",
    "\n",
    "exports_phaseone.reset_index(inplace = True)\n",
    "\n",
    "exports_phaseone.set_index([\"naics3\"], inplace = True)\n",
    "\n",
    "##################################################################\n",
    "\n",
    "exports_phaseone.rename(mapper = {\"china_exports\": \"phase_one_exports\"}, inplace = True, axis = 1)\n",
    "\n",
    "exports_by_naics = exports_by_naics.merge(exports_phaseone, \n",
    "                                          left_on = [\"naics3\", \"time\"], right_on = [\"naics3\", \"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>china_exports</th>\n",
       "      <th>phase_one_exports</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naics3</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>5514834.0</td>\n",
       "      <td>9168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>370878626.0</td>\n",
       "      <td>285736862.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>118177237.0</td>\n",
       "      <td>2631482.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>7866133.0</td>\n",
       "      <td>6732301.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>81213615.0</td>\n",
       "      <td>417839.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             time  china_exports  phase_one_exports\n",
       "naics3                                             \n",
       "337    2020-04-01      5514834.0             9168.0\n",
       "339    2020-04-01    370878626.0        285736862.0\n",
       "910    2020-04-01    118177237.0          2631482.0\n",
       "930    2020-04-01      7866133.0          6732301.0\n",
       "990    2020-04-01     81213615.0           417839.0"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exports_by_naics.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions do the following: \n",
    "\n",
    "1. Grab the BLS QCEW file for 2017\n",
    "\n",
    "2. Then create the exports per worker measure at the county level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_bls():\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"**********************************************************************************\")\n",
    "    print(\"Downloading and processing BLS file\")\n",
    "    print(\"\")\n",
    "\n",
    "    url = \"https://data.bls.gov/cew/data/files/2017/csv/2017_annual_singlefile.zip\"\n",
    "# This will read in the annual, single file. It's big, but has all we want...\n",
    "\n",
    "    r = requests.get(url) \n",
    "\n",
    "# convert bytes to zip file  \n",
    "    bls_sf = zf.ZipFile(io.BytesIO(r.content)) \n",
    "    print('Type of zipfile object:', type(bls_sf))\n",
    "\n",
    "    clist = ['area_fips', 'own_code', 'industry_code', 'agglvl_code', 'size_code',\n",
    "       'year', 'disclosure_code', 'annual_avg_estabs',\n",
    "       'annual_avg_emplvl', 'total_annual_wages','avg_annual_pay']\n",
    "\n",
    "    df = pd.read_csv(bls_sf.open(bls_sf.namelist()[0]), usecols= clist)\n",
    "\n",
    "########################################################################\n",
    "\n",
    "    NAICS_county_level = 75 \n",
    "# This is the code that will select only counties at the 3 digit NAICS level\n",
    "\n",
    "    df_county = df[df.agglvl_code == NAICS_county_level].copy()\n",
    "\n",
    "    df_county = df_county[df_county.own_code == 5]\n",
    "# Only grab private stuff\n",
    "\n",
    "    df_county = df_county[(df_county.area_fips.str[0:2] != \"72\") & (df_county.area_fips.str[0:2] != \"78\")\n",
    "              & (df_county.area_fips.str[0:2] != \"02\") & (df_county.area_fips.str[0:2] != \"15\")]\n",
    "#Drop puerto rico, alaska, hawaii...this mayb not be doing what I think it is...as it looks like these guys are there\n",
    "# Does not matter as analysis is performed withthem, drop them when do the map. \n",
    "\n",
    "    df_county[\"sup_ind\"] = df_county.industry_code.str[1].astype(int)\n",
    "# sometimes there are super industries floating around we want to drop them.\n",
    "# not clear if this matters with the conditioning all ready\n",
    "\n",
    "    df_county = df_county[df_county[\"sup_ind\"] > 0]\n",
    "\n",
    "    df_county.area_fips = df_county.area_fips.astype(str)\n",
    "\n",
    "    df_national = df_county.groupby(\"industry_code\").agg({\"annual_avg_emplvl\": \"sum\"})\n",
    "\n",
    "    df_national.reset_index(inplace = True)\n",
    "\n",
    "    df_national.rename({\"annual_avg_emplvl\":\"nat_emplvl\"}, axis = 1, inplace = True)\n",
    "    \n",
    "    return df_county, df_national"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trade_weights(df):\n",
    "    # Takes in the county groupings and will return, for each county, a time series of export\n",
    "    # exposure, tariffs, and other statistics. \n",
    "\n",
    "    new_df = df.merge(df_national[[\"nat_emplvl\",\n",
    "                                   \"industry_code\"]],\n",
    "                                  how = \"outer\", left_on = \"industry_code\", right_on = \"industry_code\")\n",
    "    # Merge the nation with the county, why, we want to make sure all the naics codes are lined up properly\n",
    "        \n",
    "    new_df[\"emp_wts\"] = (new_df.annual_avg_emplvl/new_df.nat_emplvl)\n",
    "     \n",
    "    # create the weights...\n",
    "        \n",
    "    foo_df = exports_by_naics.merge(new_df[[\"emp_wts\",\n",
    "                                           \"industry_code\",\n",
    "                                          \"annual_avg_emplvl\"]], left_index = True, right_on = \"industry_code\")  \n",
    "    \n",
    "    # Now each weight is for a NAICS code, we will merge it with the export trade data set, so for all naics, all time...\n",
    "    # This is a big df whith all trade data and then the county's weights for each naics code\n",
    "    \n",
    "    foo_grp = foo_df.groupby(\"time\")\n",
    "    \n",
    "    # group by time. \n",
    "    \n",
    "    foo = foo_grp.apply(trade_by_naics)\n",
    "    \n",
    "    # Then for each time gropuing, we aggregate across the naics codes according to the weights above.\n",
    "    \n",
    "    foo = foo.droplevel(1)\n",
    "    \n",
    "    foo[\"fips\"] = df[\"area_fips\"].astype(str).iloc[0]\n",
    "    \n",
    "    # some cleaning of the df\n",
    "    \n",
    "    foo[\"total_employment\"] = new_df.annual_avg_emplvl.sum()\n",
    "    \n",
    "    # get total employment.\n",
    "    \n",
    "    return pd.DataFrame(foo)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trade_by_naics(df):\n",
    "    # Simple function just to test about aggregation \n",
    "\n",
    "    china_exp_pc = (1/df[\"annual_avg_emplvl\"].sum())*(df[\"china_exports\"]*df[\"emp_wts\"]).sum()\n",
    "    \n",
    "    china_pho_pc = (1/df[\"annual_avg_emplvl\"].sum())*(df[\"phase_one_exports\"]*df[\"emp_wts\"]).sum()\n",
    "    # the first term multiplies trade by the county's share of national level employment\n",
    "    # then the outside term divides by number of workers in a county. \n",
    "    \n",
    "    foo = {\"china_exp_pc\": [china_exp_pc],\n",
    "           \"china_pho_pc\": [china_pho_pc],\n",
    "          \"emplvl_2017\": df[\"annual_avg_emplvl\"].sum()}\n",
    "\n",
    "    return pd.DataFrame(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**********************************************************************************\n",
      "Downloading and processing BLS file\n",
      "\n",
      "Type of zipfile object: <class 'zipfile.ZipFile'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3254: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_county, df_national = download_bls()\n",
    "\n",
    "#print(df_county.annual_avg_emplvl.sum())\n",
    "\n",
    "grp = df_county.groupby(\"area_fips\")\n",
    "\n",
    "trade_county = grp.apply(create_trade_weights)\n",
    "\n",
    "trade_county[\"china_exp_pc\"] = (trade_county[\"emplvl_2017\"]/\n",
    "                                    trade_county[\"total_employment\"])*trade_county[\"china_exp_pc\"]\n",
    "\n",
    "trade_county[\"china_pho_pc\"] = (trade_county[\"emplvl_2017\"]/\n",
    "                                    trade_county[\"total_employment\"])*trade_county[\"china_pho_pc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>china_exp_pc</th>\n",
       "      <th>china_pho_pc</th>\n",
       "      <th>emplvl_2017</th>\n",
       "      <th>fips</th>\n",
       "      <th>total_employment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_fips</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">10001</th>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>58.576866</td>\n",
       "      <td>53.597833</td>\n",
       "      <td>2843.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>29514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-01</th>\n",
       "      <td>48.538294</td>\n",
       "      <td>43.914389</td>\n",
       "      <td>2843.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>29514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-01</th>\n",
       "      <td>42.466573</td>\n",
       "      <td>37.635078</td>\n",
       "      <td>2843.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>29514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-01</th>\n",
       "      <td>33.938510</td>\n",
       "      <td>29.675054</td>\n",
       "      <td>2843.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>29514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-01</th>\n",
       "      <td>34.109425</td>\n",
       "      <td>30.018439</td>\n",
       "      <td>2843.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>29514.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      china_exp_pc  china_pho_pc  emplvl_2017   fips  \\\n",
       "area_fips time                                                         \n",
       "10001     2017-01-01     58.576866     53.597833       2843.0  10001   \n",
       "          2017-02-01     48.538294     43.914389       2843.0  10001   \n",
       "          2017-03-01     42.466573     37.635078       2843.0  10001   \n",
       "          2017-04-01     33.938510     29.675054       2843.0  10001   \n",
       "          2017-05-01     34.109425     30.018439       2843.0  10001   \n",
       "\n",
       "                      total_employment  \n",
       "area_fips time                          \n",
       "10001     2017-01-01           29514.0  \n",
       "          2017-02-01           29514.0  \n",
       "          2017-03-01           29514.0  \n",
       "          2017-04-01           29514.0  \n",
       "          2017-05-01           29514.0  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_county.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>china_exp_pc</th>\n",
       "      <th>china_pho_pc</th>\n",
       "      <th>emplvl_2017</th>\n",
       "      <th>fips</th>\n",
       "      <th>total_employment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_fips</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">10001</th>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>58.576866</td>\n",
       "      <td>53.597833</td>\n",
       "      <td>2843.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>29514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-01</th>\n",
       "      <td>48.538294</td>\n",
       "      <td>43.914389</td>\n",
       "      <td>2843.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>29514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-01</th>\n",
       "      <td>42.466573</td>\n",
       "      <td>37.635078</td>\n",
       "      <td>2843.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>29514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-01</th>\n",
       "      <td>33.938510</td>\n",
       "      <td>29.675054</td>\n",
       "      <td>2843.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>29514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-01</th>\n",
       "      <td>34.109425</td>\n",
       "      <td>30.018439</td>\n",
       "      <td>2843.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>29514.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      china_exp_pc  china_pho_pc  emplvl_2017   fips  \\\n",
       "area_fips time                                                         \n",
       "10001     2017-01-01     58.576866     53.597833       2843.0  10001   \n",
       "          2017-02-01     48.538294     43.914389       2843.0  10001   \n",
       "          2017-03-01     42.466573     37.635078       2843.0  10001   \n",
       "          2017-04-01     33.938510     29.675054       2843.0  10001   \n",
       "          2017-05-01     34.109425     30.018439       2843.0  10001   \n",
       "\n",
       "                      total_employment  \n",
       "area_fips time                          \n",
       "10001     2017-01-01           29514.0  \n",
       "          2017-02-01           29514.0  \n",
       "          2017-03-01           29514.0  \n",
       "          2017-04-01           29514.0  \n",
       "          2017-05-01           29514.0  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_county.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we are set. The only final part is to add in some information from the census. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_api_key = '34e40301bda77077e24c859c6c6c0b721ad73fc7'\n",
    "# This is my api_key\n",
    "\n",
    "c = Census(my_api_key)\n",
    "# This will create an object c which has methods associated with it.\n",
    "# We will see  these below.\n",
    "\n",
    "type(c) \n",
    "# Per the discussion below, try c.tab and see the options. \n",
    "\n",
    "code = (\"NAME\",\"B01001_001E\",\"B19013_001E\") # Same Codes:\n",
    "\n",
    "county_2017 = pd.DataFrame(c.acs5.get(code, \n",
    "                                         {'for': 'county:*'}, year=2017))\n",
    "                                         # Same deal, but we specify county then the wild card\n",
    "                                         # On the example page, there are ways do do this, only by state\n",
    "        \n",
    "county_2017 = county_2017.rename(columns = {\"B01001_001E\":\"2017_population\", \"B19013_001E\":\"2017_income\"})\n",
    "\n",
    "county_2017[\"GEOFIPS\"] = (county_2017[\"state\"] + county_2017[\"county\"]).astype(int)\n",
    "\n",
    "county_2017[\"2017_population\"] = county_2017[\"2017_population\"].astype(float)\n",
    "\n",
    "county_2017[\"2017_income\"] = county_2017[\"2017_income\"].astype(float)\n",
    "\n",
    "county_2017.set_index([\"GEOFIPS\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_county.reset_index(inplace = True)\n",
    "\n",
    "trade_county[\"int_area_fips\"] = trade_county[\"area_fips\"].astype(int)\n",
    "\n",
    "trade_county = trade_county.merge(county_2017[[\"2017_income\",\"2017_population\"]],\n",
    "                                  left_on = \"int_area_fips\", right_index = True, how = \"left\")\n",
    "\n",
    "#trade_employ.drop(labels = \"index\", axis = 1, inplace = True)\n",
    "\n",
    "trade_county.set_index([\"area_fips\", \"time\"],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>china_exp_pc</th>\n",
       "      <th>china_pho_pc</th>\n",
       "      <th>emplvl_2017</th>\n",
       "      <th>fips</th>\n",
       "      <th>total_employment</th>\n",
       "      <th>int_area_fips</th>\n",
       "      <th>2017_income</th>\n",
       "      <th>2017_population</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_fips</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">10001</th>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>58.576866</td>\n",
       "      <td>53.597833</td>\n",
       "      <td>2843.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>29514.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>57647.0</td>\n",
       "      <td>173145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-01</th>\n",
       "      <td>48.538294</td>\n",
       "      <td>43.914389</td>\n",
       "      <td>2843.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>29514.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>57647.0</td>\n",
       "      <td>173145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-01</th>\n",
       "      <td>42.466573</td>\n",
       "      <td>37.635078</td>\n",
       "      <td>2843.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>29514.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>57647.0</td>\n",
       "      <td>173145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-01</th>\n",
       "      <td>33.938510</td>\n",
       "      <td>29.675054</td>\n",
       "      <td>2843.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>29514.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>57647.0</td>\n",
       "      <td>173145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-01</th>\n",
       "      <td>34.109425</td>\n",
       "      <td>30.018439</td>\n",
       "      <td>2843.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>29514.0</td>\n",
       "      <td>10001</td>\n",
       "      <td>57647.0</td>\n",
       "      <td>173145.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      china_exp_pc  china_pho_pc  emplvl_2017   fips  \\\n",
       "area_fips time                                                         \n",
       "10001     2017-01-01     58.576866     53.597833       2843.0  10001   \n",
       "          2017-02-01     48.538294     43.914389       2843.0  10001   \n",
       "          2017-03-01     42.466573     37.635078       2843.0  10001   \n",
       "          2017-04-01     33.938510     29.675054       2843.0  10001   \n",
       "          2017-05-01     34.109425     30.018439       2843.0  10001   \n",
       "\n",
       "                      total_employment  int_area_fips  2017_income  \\\n",
       "area_fips time                                                       \n",
       "10001     2017-01-01           29514.0          10001      57647.0   \n",
       "          2017-02-01           29514.0          10001      57647.0   \n",
       "          2017-03-01           29514.0          10001      57647.0   \n",
       "          2017-04-01           29514.0          10001      57647.0   \n",
       "          2017-05-01           29514.0          10001      57647.0   \n",
       "\n",
       "                      2017_population  \n",
       "area_fips time                         \n",
       "10001     2017-01-01         173145.0  \n",
       "          2017-02-01         173145.0  \n",
       "          2017-03-01         173145.0  \n",
       "          2017-04-01         173145.0  \n",
       "          2017-05-01         173145.0  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_county.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path =  \".\\\\data\"+ \"\\\\phase_one_county.parquet\"\n",
    "\n",
    "pq.write_table(pa.Table.from_pandas(trade_county), file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the ``phase_one_county.parquet`` file is the main file used in the ``phase-one-map.ipynb`` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
