{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd             # data package\n",
    "import matplotlib.pyplot as plt # graphics \n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from census import Census # This is new...\n",
    "\n",
    "import requests, io             # internet and input tools  \n",
    "import zipfile as zf            # zip file tools \n",
    "import os  \n",
    "\n",
    "#import weightedcalcs as wc\n",
    "#import numpy as np\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file creates the trade file behind the [Phase One Tracker](https://www.tradewartracker.com/). It proceeds in several steps.\n",
    "\n",
    "1. Grabs the trade data\n",
    "\n",
    "2. Constructs the relavent Phase One product catagories and the associated goals/targets.\n",
    "\n",
    "3. Maps the data to the county level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_type = \"exports\"\n",
    "\n",
    "my_key = \"&key=34e40301bda77077e24c859c6c6c0b721ad73fc7\"\n",
    "# This is my key. I'm nice and I have it posted. If you will be doing more with this\n",
    "# please get your own key!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Grabe the trade data using the Census's API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def census_trade(url, trade_type, country, product_level):\n",
    "    \n",
    "    r = requests.get(url) \n",
    "    \n",
    "    print(r)\n",
    "    \n",
    "    df = pd.DataFrame(r.json()[1:]) # This then converts it to a dataframe\n",
    "    # Note that the first entry is the labels\n",
    "\n",
    "    df.columns = r.json()[0]\n",
    "\n",
    "    df.time = pd.to_datetime(df.time, format=\"%Y-%m\")\n",
    "    # This is so I can call this correctly...\n",
    "    \n",
    "    if trade_type == \"imports\":\n",
    "        \n",
    "        trade_label = country + \"_\" + trade_type\n",
    "        \n",
    "        df[trade_label] = df[\"CON_VAL_MO\"].astype(float)\n",
    "        \n",
    "        df[product_level] = df[\"I_COMMODITY\"].astype(str)\n",
    "        \n",
    "        df.drop([\"CON_VAL_MO\", \"I_COMMODITY\", \"COMM_LVL\"], axis = 1, inplace = True)\n",
    "        \n",
    "    if trade_type == \"exports\":\n",
    "    \n",
    "        trade_label = country + \"_\" + trade_type\n",
    "        \n",
    "        df[trade_label] = df[\"ALL_VAL_MO\"].astype(float)\n",
    "\n",
    "        df[product_level] = df[\"E_COMMODITY\"].astype(str)\n",
    "        \n",
    "        df.drop([\"ALL_VAL_MO\", \"E_COMMODITY\", \"COMM_LVL\"], axis = 1, inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-05-01 00:00:00')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_use = \"hs?get=E_COMMODITY,ALL_VAL_MO\"\n",
    "\n",
    "url = \"https://api.census.gov/data/timeseries/intltrade/exports/\" + end_use \n",
    "url = url + my_key + \"&time==from+2013-01\" + \"&COMM_LVL=HS6\"\n",
    "\n",
    "url = url + \"&CTY_CODE=5700\"\n",
    "\n",
    "df = census_trade(url, trade_type, \"china\", \"hs6\")\n",
    "\n",
    "df[\"hs4\"] = df[\"hs6\"].str[0:4]\n",
    "\n",
    "df.time.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>CTY_CODE</th>\n",
       "      <th>china_exports</th>\n",
       "      <th>hs6</th>\n",
       "      <th>hs4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>5700</td>\n",
       "      <td>4806.0</td>\n",
       "      <td>841090</td>\n",
       "      <td>8410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>5700</td>\n",
       "      <td>287000.0</td>\n",
       "      <td>481031</td>\n",
       "      <td>4810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>5700</td>\n",
       "      <td>311650.0</td>\n",
       "      <td>481160</td>\n",
       "      <td>4811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>5700</td>\n",
       "      <td>63701.0</td>\n",
       "      <td>481620</td>\n",
       "      <td>4816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>5700</td>\n",
       "      <td>40265.0</td>\n",
       "      <td>490290</td>\n",
       "      <td>4902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time CTY_CODE  china_exports     hs6   hs4\n",
       "0 2013-01-01     5700         4806.0  841090  8410\n",
       "1 2013-01-01     5700       287000.0  481031  4810\n",
       "2 2013-01-01     5700       311650.0  481160  4811\n",
       "3 2013-01-01     5700        63701.0  481620  4816\n",
       "4 2013-01-01     5700        40265.0  490290  4902"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Bring in the Phase One Product list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfproducts = pd.read_csv(\".\\\\data\"+ \"\\\\annex-6-1.csv\", dtype = {\"hs4\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phaseone = df.merge(dfproducts, left_on = \"hs4\", right_on = \"hs4\", how = \"left\", indicator = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "concordance = pq.read_table(\".\\\\data\\\\alt_concordance.parquet\").to_pandas()\n",
    "\n",
    "concordance.head()\n",
    "\n",
    "dict_concordance = dict(zip(concordance.hs6,concordance.naics)) \n",
    "\n",
    "df_phaseone[\"naics\"] = df_phaseone[\"hs6\"].map(dict_concordance)\n",
    "\n",
    "df_phaseone[\"naics3\"] = df_phaseone[\"naics\"].str[0:3]\n",
    "# The NAICS codes are for mapping the data to the county level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phaseone.high_catagory = df_phaseone.high_catagory.fillna(\"not in aggreement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the outfiles ``phaseone-tradedata.parquet`` is the main file used in ``phase-one-plots.ipynb`` notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \".\\\\data\"+ \"\\\\phaseone-tradedata.parquet\"\n",
    "\n",
    "pq.write_table(pa.Table.from_pandas(df_phaseone), out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This then constructs the benchmark and goal measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phaseone.set_index(\"time\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = df_phaseone.loc[\"2017\"].groupby(\"high_catagory\")\n",
    "\n",
    "benchmarks = grp.agg({\"china_exports\": \"sum\"})\n",
    "\n",
    "benchmarks.columns = [\"2017 Values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = df_phaseone.loc[\"2020\"].groupby(\"high_catagory\")\n",
    "\n",
    "current = grp.agg({\"china_exports\": \"sum\"})\n",
    "\n",
    "current.columns = [\"2020 Values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks = benchmarks.merge(current, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the goals from the AGREEMENT\n",
    "\n",
    "benchmarks[\"Goals\"] = 32900000000\n",
    "\n",
    "benchmarks.iloc[1,2] = 12500000000\n",
    "\n",
    "benchmarks.iloc[2,2] = 18500000000\n",
    "\n",
    "benchmarks.iloc[3,2] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the ``phaseone-goals.parquet`` file is the data file used to create the bar graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \".\\\\data\"+ \"\\\\phaseone-goals.parquet\"\n",
    "\n",
    "pq.write_table(pa.Table.from_pandas(benchmarks), out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2017 Values</th>\n",
       "      <th>2020 Values</th>\n",
       "      <th>Goals</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_catagory</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. Manufactured Goods</th>\n",
       "      <td>5.043786e+10</td>\n",
       "      <td>1.947985e+10</td>\n",
       "      <td>3.290000e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. Agriculture</th>\n",
       "      <td>2.125617e+10</td>\n",
       "      <td>5.585255e+09</td>\n",
       "      <td>1.250000e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. Energy</th>\n",
       "      <td>1.592206e+10</td>\n",
       "      <td>3.505937e+09</td>\n",
       "      <td>1.850000e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not in aggreement</th>\n",
       "      <td>5.026467e+10</td>\n",
       "      <td>1.331000e+10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        2017 Values   2020 Values         Goals\n",
       "high_catagory                                                  \n",
       "1. Manufactured Goods  5.043786e+10  1.947985e+10  3.290000e+10\n",
       "2. Agriculture         2.125617e+10  5.585255e+09  1.250000e+10\n",
       "3. Energy              1.592206e+10  3.505937e+09  1.850000e+10\n",
       "not in aggreement      5.026467e+10  1.331000e+10           NaN"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### The code below then performs the projection of the data down to the county level\n",
    "\n",
    "The first step is to group on NAICS. Note that how this is constructed is only Phase One coverd products are included. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CTY_CODE</th>\n",
       "      <th>china_exports</th>\n",
       "      <th>hs6</th>\n",
       "      <th>hs4</th>\n",
       "      <th>description</th>\n",
       "      <th>low_catagory</th>\n",
       "      <th>high_catagory</th>\n",
       "      <th>_merge</th>\n",
       "      <th>naics</th>\n",
       "      <th>naics3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>5700</td>\n",
       "      <td>753280.0</td>\n",
       "      <td>200899</td>\n",
       "      <td>2008</td>\n",
       "      <td>Fruit, nuts and other edible parts of plants, ...</td>\n",
       "      <td>Other agricultural commodities</td>\n",
       "      <td>2. Agriculture</td>\n",
       "      <td>both</td>\n",
       "      <td>311421</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>5700</td>\n",
       "      <td>361441.0</td>\n",
       "      <td>151800</td>\n",
       "      <td>1518</td>\n",
       "      <td>Animal or vegetable fats, oils and their fract...</td>\n",
       "      <td>Other agricultural commodities</td>\n",
       "      <td>2. Agriculture</td>\n",
       "      <td>both</td>\n",
       "      <td>311613</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>5700</td>\n",
       "      <td>289709.0</td>\n",
       "      <td>152000</td>\n",
       "      <td>1520</td>\n",
       "      <td>Glycerol (glycerine), whether or not pure; gly...</td>\n",
       "      <td>Other agricultural commodities</td>\n",
       "      <td>2. Agriculture</td>\n",
       "      <td>both</td>\n",
       "      <td>325611</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>5700</td>\n",
       "      <td>36631.0</td>\n",
       "      <td>152110</td>\n",
       "      <td>1521</td>\n",
       "      <td>Vegetable waxes (other than triglycerides), be...</td>\n",
       "      <td>Other agricultural commodities</td>\n",
       "      <td>2. Agriculture</td>\n",
       "      <td>both</td>\n",
       "      <td>325998</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>5700</td>\n",
       "      <td>2285893.0</td>\n",
       "      <td>160239</td>\n",
       "      <td>1602</td>\n",
       "      <td>Other prepared or preserved meat, meat offal o...</td>\n",
       "      <td>Meat</td>\n",
       "      <td>2. Agriculture</td>\n",
       "      <td>both</td>\n",
       "      <td>311615</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-01</th>\n",
       "      <td>5700</td>\n",
       "      <td>23320264.0</td>\n",
       "      <td>852351</td>\n",
       "      <td>8523</td>\n",
       "      <td>Discs, tapes, solid-state non-volatile storage...</td>\n",
       "      <td>Electrical equipment and mac.hioery</td>\n",
       "      <td>1. Manufactured Goods</td>\n",
       "      <td>both</td>\n",
       "      <td>334613</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-01</th>\n",
       "      <td>5700</td>\n",
       "      <td>341171.0</td>\n",
       "      <td>852352</td>\n",
       "      <td>8523</td>\n",
       "      <td>Discs, tapes, solid-state non-volatile storage...</td>\n",
       "      <td>Electrical equipment and mac.hioery</td>\n",
       "      <td>1. Manufactured Goods</td>\n",
       "      <td>both</td>\n",
       "      <td>334413</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-01</th>\n",
       "      <td>5700</td>\n",
       "      <td>32764.0</td>\n",
       "      <td>852359</td>\n",
       "      <td>8523</td>\n",
       "      <td>Discs, tapes, solid-state non-volatile storage...</td>\n",
       "      <td>Electrical equipment and mac.hioery</td>\n",
       "      <td>1. Manufactured Goods</td>\n",
       "      <td>both</td>\n",
       "      <td>334613</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-01</th>\n",
       "      <td>5700</td>\n",
       "      <td>327850.0</td>\n",
       "      <td>852380</td>\n",
       "      <td>8523</td>\n",
       "      <td>Discs, tapes, solid-state non-volatile storage...</td>\n",
       "      <td>Electrical equipment and mac.hioery</td>\n",
       "      <td>1. Manufactured Goods</td>\n",
       "      <td>both</td>\n",
       "      <td>334614</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-01</th>\n",
       "      <td>5700</td>\n",
       "      <td>1105942.0</td>\n",
       "      <td>852550</td>\n",
       "      <td>8525</td>\n",
       "      <td>Transmission apparatus for radio-broadcasting ...</td>\n",
       "      <td>Electrical equipment and mac.hioery</td>\n",
       "      <td>1. Manufactured Goods</td>\n",
       "      <td>both</td>\n",
       "      <td>334220</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155758 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           CTY_CODE  china_exports     hs6   hs4  \\\n",
       "time                                               \n",
       "2017-01-01     5700       753280.0  200899  2008   \n",
       "2017-01-01     5700       361441.0  151800  1518   \n",
       "2017-01-01     5700       289709.0  152000  1520   \n",
       "2017-01-01     5700        36631.0  152110  1521   \n",
       "2017-01-01     5700      2285893.0  160239  1602   \n",
       "...             ...            ...     ...   ...   \n",
       "2020-05-01     5700     23320264.0  852351  8523   \n",
       "2020-05-01     5700       341171.0  852352  8523   \n",
       "2020-05-01     5700        32764.0  852359  8523   \n",
       "2020-05-01     5700       327850.0  852380  8523   \n",
       "2020-05-01     5700      1105942.0  852550  8525   \n",
       "\n",
       "                                                  description  \\\n",
       "time                                                            \n",
       "2017-01-01  Fruit, nuts and other edible parts of plants, ...   \n",
       "2017-01-01  Animal or vegetable fats, oils and their fract...   \n",
       "2017-01-01  Glycerol (glycerine), whether or not pure; gly...   \n",
       "2017-01-01  Vegetable waxes (other than triglycerides), be...   \n",
       "2017-01-01  Other prepared or preserved meat, meat offal o...   \n",
       "...                                                       ...   \n",
       "2020-05-01  Discs, tapes, solid-state non-volatile storage...   \n",
       "2020-05-01  Discs, tapes, solid-state non-volatile storage...   \n",
       "2020-05-01  Discs, tapes, solid-state non-volatile storage...   \n",
       "2020-05-01  Discs, tapes, solid-state non-volatile storage...   \n",
       "2020-05-01  Transmission apparatus for radio-broadcasting ...   \n",
       "\n",
       "                                   low_catagory          high_catagory _merge  \\\n",
       "time                                                                            \n",
       "2017-01-01       Other agricultural commodities         2. Agriculture   both   \n",
       "2017-01-01       Other agricultural commodities         2. Agriculture   both   \n",
       "2017-01-01       Other agricultural commodities         2. Agriculture   both   \n",
       "2017-01-01       Other agricultural commodities         2. Agriculture   both   \n",
       "2017-01-01                                 Meat         2. Agriculture   both   \n",
       "...                                         ...                    ...    ...   \n",
       "2020-05-01  Electrical equipment and mac.hioery  1. Manufactured Goods   both   \n",
       "2020-05-01  Electrical equipment and mac.hioery  1. Manufactured Goods   both   \n",
       "2020-05-01  Electrical equipment and mac.hioery  1. Manufactured Goods   both   \n",
       "2020-05-01  Electrical equipment and mac.hioery  1. Manufactured Goods   both   \n",
       "2020-05-01  Electrical equipment and mac.hioery  1. Manufactured Goods   both   \n",
       "\n",
       "             naics naics3  \n",
       "time                       \n",
       "2017-01-01  311421    311  \n",
       "2017-01-01  311613    311  \n",
       "2017-01-01  325611    325  \n",
       "2017-01-01  325998    325  \n",
       "2017-01-01  311615    311  \n",
       "...            ...    ...  \n",
       "2020-05-01  334613    334  \n",
       "2020-05-01  334413    334  \n",
       "2020-05-01  334613    334  \n",
       "2020-05-01  334614    334  \n",
       "2020-05-01  334220    334  \n",
       "\n",
       "[155758 rows x 10 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_phaseone.loc[\"2017\":]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phaseone = df_phaseone.loc[\"2017\":]\n",
    "\n",
    "grp = df_phaseone.groupby([\"time\",\"naics3\"])\n",
    "\n",
    "exports_by_naics = grp.agg({\"china_exports\": \"sum\"})\n",
    "\n",
    "exports_by_naics.reset_index(inplace = True)\n",
    "\n",
    "exports_by_naics.set_index([\"naics3\"], inplace = True)\n",
    "\n",
    "##################################################################\n",
    "\n",
    "grp = df_phaseone[df_phaseone[\"high_catagory\"] != \"not in aggreement\"].groupby([\"time\",\"naics3\"])\n",
    "\n",
    "exports_phaseone = grp.agg({\"china_exports\": \"sum\"})\n",
    "\n",
    "exports_phaseone.reset_index(inplace = True)\n",
    "\n",
    "exports_phaseone.set_index([\"naics3\"], inplace = True)\n",
    "\n",
    "##################################################################\n",
    "\n",
    "exports_phaseone.rename(mapper = {\"china_exports\": \"phase_one_exports\"}, inplace = True, axis = 1)\n",
    "\n",
    "exports_by_naics = exports_by_naics.merge(exports_phaseone, \n",
    "                                          left_on = [\"naics3\", \"time\"], right_on = [\"naics3\", \"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>china_exports</th>\n",
       "      <th>phase_one_exports</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naics3</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>4748678.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>357396485.0</td>\n",
       "      <td>308669410.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>121597022.0</td>\n",
       "      <td>4654176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>10236239.0</td>\n",
       "      <td>4171017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>101889086.0</td>\n",
       "      <td>284077.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             time  china_exports  phase_one_exports\n",
       "naics3                                             \n",
       "337    2020-05-01      4748678.0                0.0\n",
       "339    2020-05-01    357396485.0        308669410.0\n",
       "910    2020-05-01    121597022.0          4654176.0\n",
       "930    2020-05-01     10236239.0          4171017.0\n",
       "990    2020-05-01    101889086.0           284077.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exports_by_naics.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions do the following: \n",
    "\n",
    "1. Grab the BLS QCEW file for 2017\n",
    "\n",
    "2. Then create the exports per worker measure at the county level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_bls():\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"**********************************************************************************\")\n",
    "    print(\"Downloading and processing BLS file\")\n",
    "    print(\"\")\n",
    "\n",
    "    url = \"https://data.bls.gov/cew/data/files/2017/csv/2017_annual_singlefile.zip\"\n",
    "# This will read in the annual, single file. It's big, but has all we want...\n",
    "\n",
    "    r = requests.get(url) \n",
    "\n",
    "# convert bytes to zip file  \n",
    "    bls_sf = zf.ZipFile(io.BytesIO(r.content)) \n",
    "    print('Type of zipfile object:', type(bls_sf))\n",
    "\n",
    "    clist = ['area_fips', 'own_code', 'industry_code', 'agglvl_code', 'size_code',\n",
    "       'year', 'disclosure_code', 'annual_avg_estabs',\n",
    "       'annual_avg_emplvl', 'total_annual_wages','avg_annual_pay']\n",
    "\n",
    "    df = pd.read_csv(bls_sf.open(bls_sf.namelist()[0]), usecols= clist)\n",
    "\n",
    "########################################################################\n",
    "\n",
    "    NAICS_county_level = 75 \n",
    "# This is the code that will select only counties at the 3 digit NAICS level\n",
    "\n",
    "    df_county = df[df.agglvl_code == NAICS_county_level].copy()\n",
    "\n",
    "    df_county = df_county[df_county.own_code == 5]\n",
    "# Only grab private stuff\n",
    "\n",
    "    df_county = df_county[(df_county.area_fips.str[0:2] != \"72\") & (df_county.area_fips.str[0:2] != \"78\")\n",
    "              & (df_county.area_fips.str[0:2] != \"02\") & (df_county.area_fips.str[0:2] != \"15\")]\n",
    "#Drop puerto rico, alaska, hawaii...this mayb not be doing what I think it is...as it looks like these guys are there\n",
    "# Does not matter as analysis is performed withthem, drop them when do the map. \n",
    "\n",
    "    df_county[\"sup_ind\"] = df_county.industry_code.str[1].astype(int)\n",
    "# sometimes there are super industries floating around we want to drop them.\n",
    "# not clear if this matters with the conditioning all ready\n",
    "\n",
    "    df_county = df_county[df_county[\"sup_ind\"] > 0]\n",
    "\n",
    "    df_county.area_fips = df_county.area_fips.astype(str)\n",
    "\n",
    "    df_national = df_county.groupby(\"industry_code\").agg({\"annual_avg_emplvl\": \"sum\"})\n",
    "\n",
    "    df_national.reset_index(inplace = True)\n",
    "\n",
    "    df_national.rename({\"annual_avg_emplvl\":\"nat_emplvl\"}, axis = 1, inplace = True)\n",
    "    \n",
    "    return df_county, df_national"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trade_weights(df):\n",
    "    # Takes in the county groupings and will return, for each county, a time series of export\n",
    "    # exposure, tariffs, and other statistics. \n",
    "\n",
    "    new_df = df.merge(df_national[[\"nat_emplvl\",\n",
    "                                   \"industry_code\"]],\n",
    "                                  how = \"outer\", left_on = \"industry_code\", right_on = \"industry_code\")\n",
    "    # Merge the nation with the county, why, we want to make sure all the naics codes are lined up properly\n",
    "        \n",
    "    new_df[\"emp_wts\"] = (new_df.annual_avg_emplvl/new_df.nat_emplvl)\n",
    "     \n",
    "    # create the weights...\n",
    "        \n",
    "    foo_df = exports_by_naics.merge(new_df[[\"emp_wts\",\n",
    "                                           \"industry_code\",\n",
    "                                          \"annual_avg_emplvl\"]], left_index = True, right_on = \"industry_code\")  \n",
    "    \n",
    "    # Now each weight is for a NAICS code, we will merge it with the export trade data set, so for all naics, all time...\n",
    "    # This is a big df whith all trade data and then the county's weights for each naics code\n",
    "    \n",
    "    foo_grp = foo_df.groupby(\"time\")\n",
    "    \n",
    "    # group by time. \n",
    "    \n",
    "    foo = foo_grp.apply(trade_by_naics)\n",
    "    \n",
    "    # Then for each time gropuing, we aggregate across the naics codes according to the weights above.\n",
    "    \n",
    "    foo = foo.droplevel(1)\n",
    "    \n",
    "    foo[\"fips\"] = df[\"area_fips\"].astype(str).iloc[0]\n",
    "    \n",
    "    # some cleaning of the df\n",
    "    \n",
    "    foo[\"total_employment\"] = new_df.annual_avg_emplvl.sum()\n",
    "    \n",
    "    # get total employment.\n",
    "    \n",
    "    return pd.DataFrame(foo)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trade_by_naics(df):\n",
    "    # Simple function just to test about aggregation \n",
    "\n",
    "    china_exp_pc = (1/df[\"annual_avg_emplvl\"].sum())*(df[\"china_exports\"]*df[\"emp_wts\"]).sum()\n",
    "    \n",
    "    china_pho_pc = (1/df[\"annual_avg_emplvl\"].sum())*(df[\"phase_one_exports\"]*df[\"emp_wts\"]).sum()\n",
    "    # the first term multiplies trade by the county's share of national level employment\n",
    "    # then the outside term divides by number of workers in a county. \n",
    "    \n",
    "    foo = {\"china_exp_pc\": [china_exp_pc],\n",
    "           \"china_pho_pc\": [china_pho_pc],\n",
    "          \"emplvl_2017\": df[\"annual_avg_emplvl\"].sum()}\n",
    "\n",
    "    return pd.DataFrame(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**********************************************************************************\n",
      "Downloading and processing BLS file\n",
      "\n",
      "Type of zipfile object: <class 'zipfile.ZipFile'>\n"
     ]
    }
   ],
   "source": [
    "df_county, df_national = download_bls()\n",
    "\n",
    "#print(df_county.annual_avg_emplvl.sum())\n",
    "\n",
    "grp = df_county.groupby(\"area_fips\")\n",
    "\n",
    "trade_county = grp.apply(create_trade_weights)\n",
    "\n",
    "trade_county[\"china_exp_pc\"] = (trade_county[\"emplvl_2017\"]/\n",
    "                                    trade_county[\"total_employment\"])*trade_county[\"china_exp_pc\"]\n",
    "\n",
    "trade_county[\"china_pho_pc\"] = (trade_county[\"emplvl_2017\"]/\n",
    "                                    trade_county[\"total_employment\"])*trade_county[\"china_pho_pc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_county.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_county.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we are set. The only final part is to add in some information from the census. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_api_key = '34e40301bda77077e24c859c6c6c0b721ad73fc7'\n",
    "# This is my api_key\n",
    "\n",
    "c = Census(my_api_key)\n",
    "# This will create an object c which has methods associated with it.\n",
    "# We will see  these below.\n",
    "\n",
    "type(c) \n",
    "# Per the discussion below, try c.tab and see the options. \n",
    "\n",
    "code = (\"NAME\",\"B01001_001E\",\"B19013_001E\") # Same Codes:\n",
    "\n",
    "county_2017 = pd.DataFrame(c.acs5.get(code, \n",
    "                                         {'for': 'county:*'}, year=2017))\n",
    "                                         # Same deal, but we specify county then the wild card\n",
    "                                         # On the example page, there are ways do do this, only by state\n",
    "        \n",
    "county_2017 = county_2017.rename(columns = {\"B01001_001E\":\"2017_population\", \"B19013_001E\":\"2017_income\"})\n",
    "\n",
    "county_2017[\"GEOFIPS\"] = (county_2017[\"state\"] + county_2017[\"county\"]).astype(int)\n",
    "\n",
    "county_2017[\"2017_population\"] = county_2017[\"2017_population\"].astype(float)\n",
    "\n",
    "county_2017[\"2017_income\"] = county_2017[\"2017_income\"].astype(float)\n",
    "\n",
    "county_2017.set_index([\"GEOFIPS\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_county.reset_index(inplace = True)\n",
    "\n",
    "trade_county[\"int_area_fips\"] = trade_county[\"area_fips\"].astype(int)\n",
    "\n",
    "trade_county = trade_county.merge(county_2017[[\"2017_income\",\"2017_population\"]],\n",
    "                                  left_on = \"int_area_fips\", right_index = True, how = \"left\")\n",
    "\n",
    "#trade_employ.drop(labels = \"index\", axis = 1, inplace = True)\n",
    "\n",
    "trade_county.set_index([\"area_fips\", \"time\"],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_county.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path =  \".\\\\data\"+ \"\\\\phase_one_county.parquet\"\n",
    "\n",
    "pq.write_table(pa.Table.from_pandas(trade_county), file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the ``phase_one_county.parquet`` file is the main file used in the ``phase-one-map.ipynb`` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
